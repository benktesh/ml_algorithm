{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2d073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.2-cp310-cp310-macosx_10_15_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting numpy>=1.22.0 (from scikit-learn)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-macosx_14_0_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in ./mlvenv/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-4.25.8-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in ./mlvenv/lib/python3.10/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./mlvenv/lib/python3.10/site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.22.0 (from scikit-learn)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-macosx_10_9_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (34 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./mlvenv/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-macosx_10_9_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.16.2-cp310-cp310-macosx_10_15_x86_64.whl (259.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp310-cp310-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl (389 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-4.25.8-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp310-cp310-macosx_10_9_universal2.whl (209 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp310-cp310-macosx_10_9_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "Using cached markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-macosx_14_0_x86_64.whl (25.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.1/25.1 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading markupsafe-3.0.3-cp310-cp310-macosx_10_9_x86_64.whl (11 kB)\n",
      "Downloading wrapt-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl (60 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp310-cp310-macosx_10_9_x86_64.whl (353 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, joblib, idna, grpcio, google-pasta, gast, charset_normalizer, certifi, absl-py, werkzeug, scipy, requests, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, scikit-learn, rich, keras, tensorflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/37\u001b[0m [tensorflow]7\u001b[0m [tensorflow]n]ata-server]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 absl-py-2.3.1 astunparse-1.6.3 certifi-2025.11.12 charset_normalizer-3.4.4 flatbuffers-25.9.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 idna-3.11 joblib-1.5.2 keras-3.12.0 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.1.0 numpy-1.26.4 opt-einsum-3.4.0 optree-0.18.0 protobuf-4.25.8 requests-2.32.5 rich-14.2.0 scikit-learn-1.7.2 scipy-1.15.3 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.2.0 threadpoolctl-3.6.0 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.1\n",
      "Collecting tensorflow-model-optimization\n",
      "  Using cached tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
      "Collecting absl-py~=1.2 (from tensorflow-model-optimization)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting dm-tree~=0.1.1 (from tensorflow-model-optimization)\n",
      "  Downloading dm_tree-0.1.9-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: numpy~=1.23 in ./mlvenv/lib/python3.10/site-packages (from tensorflow-model-optimization) (1.26.4)\n",
      "Requirement already satisfied: six~=1.14 in ./mlvenv/lib/python3.10/site-packages (from tensorflow-model-optimization) (1.17.0)\n",
      "Collecting attrs>=18.2.0 (from dm-tree~=0.1.1->tensorflow-model-optimization)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in ./mlvenv/lib/python3.10/site-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (2.0.1)\n",
      "Using cached tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
      "Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Downloading dm_tree-0.1.9-cp310-cp310-macosx_10_9_universal2.whl (173 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: attrs, absl-py, dm-tree, tensorflow-model-optimization\n",
      "\u001b[2K  Attempting uninstall: absl-py\n",
      "\u001b[2K    Found existing installation: absl-py 2.3.1\n",
      "\u001b[2K    Uninstalling absl-py-2.3.1:\n",
      "\u001b[2K      Successfully uninstalled absl-py-2.3.1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [tensorflow-model-optimization]odel-optimization]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-1.4.0 attrs-25.4.0 dm-tree-0.1.9 tensorflow-model-optimization-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tf-keras\n",
      "  Using cached tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in ./mlvenv/lib/python3.10/site-packages (from tf-keras) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.76.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./mlvenv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mlvenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mlvenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mlvenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mlvenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./mlvenv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./mlvenv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./mlvenv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./mlvenv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in ./mlvenv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (14.2.0)\n",
      "Requirement already satisfied: namex in ./mlvenv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in ./mlvenv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./mlvenv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./mlvenv/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./mlvenv/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./mlvenv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Using cached tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install compatible versions for Python 3.10\n",
    "%pip install tensorflow==2.13.0\n",
    "%pip install tensorflow-model-optimization==0.7.5\n",
    "# Note: Don't install tf-keras separately - use TensorFlow's built-in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829ecd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 07:51:56.940743: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2965 - val_accuracy: 0.9587 - val_loss: 0.1357\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9592 - loss: 0.1400 - val_accuracy: 0.9713 - val_loss: 0.0987\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1069 - val_accuracy: 0.9707 - val_loss: 0.0898\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0892 - val_accuracy: 0.9775 - val_loss: 0.0750\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.0756 - val_accuracy: 0.9786 - val_loss: 0.0734\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Apply pruning to the model\u001b[39;00m\n\u001b[1;32m     24\u001b[0m pruning_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpruning_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m: tfmot\u001b[38;5;241m.\u001b[39msparsity\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mPolynomialDecay(initial_sparsity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, final_sparsity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, begin_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     26\u001b[0m }\n\u001b[0;32m---> 27\u001b[0m pruned_model \u001b[38;5;241m=\u001b[39m \u001b[43mtfmot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparsity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune_low_magnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpruning_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Compile the pruned model\u001b[39;00m\n\u001b[1;32m     30\u001b[0m pruned_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/repo/ml_algorithm/mlvenv/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:74\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_FAILURE_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/repo/ml_algorithm/mlvenv/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:69\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_SUCCESS_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/repo/ml_algorithm/mlvenv/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:216\u001b[0m, in \u001b[0;36mprune_low_magnitude\u001b[0;34m(to_prune, pruning_schedule, block_size, block_pooling_type, pruning_policy, sparsity_m_by_n, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m pruning_wrapper\u001b[38;5;241m.\u001b[39mPruneLowMagnitude(to_prune, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 216\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`prune_low_magnitude` can only prune an object of the following \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtypes: keras.models.Sequential, keras functional model, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    219\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.layers.Layer, list of keras.layers.Layer. You passed \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    220\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man object of type: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mto_prune\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    221\u001b[0m   )\n",
      "\u001b[0;31mValueError\u001b[0m: `prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: Sequential."
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Build a simple model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Apply pruning to the model\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.5, begin_step=0, end_step=1000)\n",
    "}\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# Compile the pruned model\n",
    "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the pruned model to finalize pruning\n",
    "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "pruned_model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test), callbacks=callbacks)\n",
    "\n",
    "# Strip pruning wrappers to remove pruning-specific layers and metadata\n",
    "pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361458df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to TensorFlow Lite with quantization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to TensorFlow Lite with quantization...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute '_get_save_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m converter = tf.lite.TFLiteConverter.from_keras_model(model)\n\u001b[32m      4\u001b[39m converter.optimizations = [tf.lite.Optimize.DEFAULT]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m quantized_model = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Save and get quantized model size\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mquantized_model.tflite\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1175\u001b[39m, in \u001b[36m_export_metrics.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1172\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(convert_func)\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1174\u001b[39m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1129\u001b[39m, in \u001b[36mTFLiteConverterBase._convert_and_export_metrics\u001b[39m\u001b[34m(self, convert_func, *args, **kwargs)\u001b[39m\n\u001b[32m   1127\u001b[39m \u001b[38;5;28mself\u001b[39m._save_conversion_params_metric()\n\u001b[32m   1128\u001b[39m start_time = time.process_time()\n\u001b[32m-> \u001b[39m\u001b[32m1129\u001b[39m result = \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1130\u001b[39m elapsed_time_ms = (time.process_time() - start_time) * \u001b[32m1000\u001b[39m\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1641\u001b[39m, in \u001b[36mTFLiteKerasModelConverterV2.convert\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[32m   1638\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n\u001b[32m   1640\u001b[39m graph_def, input_tensors, output_tensors, frozen_func = (\n\u001b[32m-> \u001b[39m\u001b[32m1641\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_freeze_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1642\u001b[39m )\n\u001b[32m   1644\u001b[39m graph_def = \u001b[38;5;28mself\u001b[39m._optimize_tf_model(\n\u001b[32m   1645\u001b[39m     graph_def, input_tensors, output_tensors, frozen_func\n\u001b[32m   1646\u001b[39m )\n\u001b[32m   1648\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(TFLiteKerasModelConverterV2, \u001b[38;5;28mself\u001b[39m).convert(\n\u001b[32m   1649\u001b[39m     graph_def, input_tensors, output_tensors\n\u001b[32m   1650\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tensorflow/lite/python/convert_phase.py:215\u001b[39m, in \u001b[36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    214\u001b[39m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[39m, in \u001b[36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    204\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m converter_error.errors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1582\u001b[39m, in \u001b[36mTFLiteKerasModelConverterV2._freeze_keras_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1573\u001b[39m \u001b[38;5;66;03m# If the model's call is not a `tf.function`, then we need to first get its\u001b[39;00m\n\u001b[32m   1574\u001b[39m \u001b[38;5;66;03m# input signature from `model_input_signature` method. We can't directly\u001b[39;00m\n\u001b[32m   1575\u001b[39m \u001b[38;5;66;03m# call `trace_model_call` because otherwise the batch dimension is set\u001b[39;00m\n\u001b[32m   1576\u001b[39m \u001b[38;5;66;03m# to None.\u001b[39;00m\n\u001b[32m   1577\u001b[39m \u001b[38;5;66;03m# Once we have better support for dynamic shapes, we can remove this.\u001b[39;00m\n\u001b[32m   1578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._keras_model.call, _def_function.Function):\n\u001b[32m   1579\u001b[39m   \u001b[38;5;66;03m# Pass `keep_original_batch_size=True` will ensure that we get an input\u001b[39;00m\n\u001b[32m   1580\u001b[39m   \u001b[38;5;66;03m# signature including the batch dimension specified by the user.\u001b[39;00m\n\u001b[32m   1581\u001b[39m   \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1582\u001b[39m   input_signature = \u001b[43m_model_input_signature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1583\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_keras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_original_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m   1584\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1586\u001b[39m \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[32m   1587\u001b[39m func = _trace_model_call(\u001b[38;5;28mself\u001b[39m._keras_model, input_signature)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tensorflow/lite/python/tflite_keras_util.py:84\u001b[39m, in \u001b[36mmodel_input_signature\u001b[39m\u001b[34m(model, keep_original_batch_size)\u001b[39m\n\u001b[32m     82\u001b[39m   input_specs = input_specs[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m   input_specs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_save_spec\u001b[49m(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m     85\u001b[39m       dynamic_batch=\u001b[38;5;129;01mnot\u001b[39;00m keep_original_batch_size)\n\u001b[32m     86\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m input_specs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Sequential' object has no attribute '_get_save_spec'"
     ]
    }
   ],
   "source": [
    "# Convert the model to a TensorFlow Lite quantized model\n",
    "print(\"Converting to TensorFlow Lite with quantization...\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_model = converter.convert()\n",
    "\n",
    "# Save and get quantized model size\n",
    "with open('quantized_model.tflite', 'wb') as f:\n",
    "    f.write(quantized_model)\n",
    "    \n",
    "quantized_size = len(quantized_model) / 1024  # Size in KB\n",
    "print(f'Quantized model size: {quantized_size:.2f} KB')\n",
    "print(f'Size reduction: {((original_size - quantized_size) / original_size * 100):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287feda1",
   "metadata": {},
   "source": [
    "## Model Quantization\n",
    "\n",
    "Convert the pruned model to TensorFlow Lite format with quantization optimization. Quantization reduces the model size and improves inference speed by converting 32-bit floating point weights and activations to 8-bit integers, while maintaining reasonable accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8d770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model accuracy: 97.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Measure accuracy of the quantized model using the test set\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "# Evaluate accuracy\n",
    "correct_predictions = 0\n",
    "for i in range(len(x_test)):\n",
    "    input_data = x_test[i:i+1].astype('float32')\n",
    "    interpreter.set_tensor(input_index, input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_index)\n",
    "    predicted_label = output.argmax()\n",
    "    if predicted_label == y_test[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(x_test)\n",
    "print(f'Quantized model accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
