{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a9fd3f",
   "metadata": {},
   "source": [
    "# Step 1: Set up the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cbec641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./mlvenv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in ./mlvenv/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in ./mlvenv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in ./mlvenv/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./mlvenv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in ./mlvenv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./mlvenv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./mlvenv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./mlvenv/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: numpy in ./mlvenv/lib/python3.12/site-packages (from torchvision) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./mlvenv/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./mlvenv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./mlvenv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./mlvenv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in ./mlvenv/lib/python3.12/site-packages (0.15.2)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in ./mlvenv/lib/python3.12/site-packages (from tokenizers) (0.36.0)\n",
      "Requirement already satisfied: filelock in ./mlvenv/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./mlvenv/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./mlvenv/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./mlvenv/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.3)\n",
      "Requirement already satisfied: requests in ./mlvenv/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./mlvenv/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mlvenv/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mlvenv/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mlvenv/lib/python3.12/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mlvenv/lib/python3.12/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mlvenv/lib/python3.12/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mlvenv/lib/python3.12/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2025.11.12)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mlvenv/lib/python3.12/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mlvenv/lib/python3.12/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mlvenv/lib/python3.12/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mlvenv/lib/python3.12/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./mlvenv/lib/python3.12/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in ./mlvenv/lib/python3.12/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./mlvenv/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./mlvenv/lib/python3.12/site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./mlvenv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./mlvenv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./mlvenv/lib/python3.12/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in ./mlvenv/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./mlvenv/lib/python3.12/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./mlvenv/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./mlvenv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./mlvenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mlvenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mlvenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./mlvenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mlvenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mlvenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mlvenv/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mlvenv/lib/python3.12/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mlvenv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mlvenv/lib/python3.12/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mlvenv/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mlvenv/lib/python3.12/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mlvenv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mlvenv/lib/python3.12/site-packages (from requests->transformers) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./mlvenv/lib/python3.12/site-packages (2.3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for Python 3.12\n",
    "%pip install torch torchvision torchaudio\n",
    "%pip install tokenizers\n",
    "%pip install transformers\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e4d23",
   "metadata": {},
   "source": [
    "# Step 2: Import libraries and load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cf353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/lq/5n9x10_s3379vpdjpp2drp5m0000gp/T/ipykernel_8054/1239606364.py\", line 1, in <module>\n",
      "    from transformers import pipeline\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/utils/__init__.py\", line 31, in <module>\n",
      "    from .generic import (\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/utils/generic.py\", line 432, in <module>\n",
      "    import torch.utils._pytree as _torch_pytree\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/lq/5n9x10_s3379vpdjpp2drp5m0000gp/T/ipykernel_8054/1239606364.py\", line 1, in <module>\n",
      "    from transformers import pipeline\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/utils/__init__.py\", line 31, in <module>\n",
      "    from .generic import (\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/utils/generic.py\", line 432, in <module>\n",
      "    import torch.utils._pytree as _torch_pytree\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/utia/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize sentiment analyzer with specific model to avoid downloading issues\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "print(\"Sentiment analysis model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c463f50",
   "metadata": {},
   "source": [
    "# Step 3: Input text for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5aa042f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Analyze the sentiment of each text\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     result = \u001b[43msentiment_analyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSentiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:156\u001b[39m, in \u001b[36mTextClassificationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    123\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m \u001b[33;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[32m    158\u001b[39m     _legacy = \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/pipelines/base.py:1140\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1133\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1134\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1137\u001b[39m         )\n\u001b[32m   1138\u001b[39m     )\n\u001b[32m   1139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/pipelines/base.py:1148\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1146\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m   1147\u001b[39m model_outputs = \u001b[38;5;28mself\u001b[39m.forward(model_inputs, **forward_params)\n\u001b[32m-> \u001b[39m\u001b[32m1148\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ml_algorithm/mlvenv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:205\u001b[39m, in \u001b[36mTextClassificationPipeline.postprocess\u001b[39m\u001b[34m(self, model_outputs, function_to_apply, top_k, _legacy)\u001b[39m\n\u001b[32m    202\u001b[39m         function_to_apply = ClassificationFunction.NONE\n\u001b[32m    204\u001b[39m outputs = model_outputs[\u001b[33m\"\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m outputs = \u001b[43moutputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m function_to_apply == ClassificationFunction.SIGMOID:\n\u001b[32m    208\u001b[39m     scores = sigmoid(outputs)\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Sample texts for sentiment analysis\n",
    "texts = [\n",
    "    \"I love this product! It's amazing.\",\n",
    "    \"The service was terrible and I'm very disappointed.\",\n",
    "    \"It's okay, not great but not bad either.\"\n",
    "]\n",
    "\n",
    "# Analyze the sentiment of each text\n",
    "for text in texts:\n",
    "    result = sentiment_analyzer(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {result[0]['label']}\")\n",
    "    print(f\"Confidence: {result[0]['score']:.2f}\")\n",
    "    print()  # Empty line for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad28a680",
   "metadata": {},
   "source": [
    "# Step 4: Test with custom input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881364b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept user input for custom sentiment analysis\n",
    "custom_text = input(\"Enter a sentence for sentiment analysis: \")\n",
    "\n",
    "# Analyze the sentiment\n",
    "result = sentiment_analyzer(custom_text)\n",
    "\n",
    "print(f\"\\nSentiment: {result[0]['label']}\")\n",
    "print(f\"Confidence: {result[0]['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db03d53",
   "metadata": {},
   "source": [
    "# Step 5: Enhance system to do analyze long text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ded4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow the model to process a longer paragraph of text\n",
    "long_text = \"\"\"\n",
    "The product is good overall, but there are some issues with battery life. \n",
    "I wish it lasted longer. However, the design is sleek, and Iâ€™m happy with the performance so far.\n",
    "\"\"\"\n",
    "result = sentiment_analyzer(long_text)\n",
    "for res in result:\n",
    "    print(f\"Sentiment: {res['label']}, Confidence: {res['score']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
