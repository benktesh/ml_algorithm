{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install compatible versions for Python 3.10\n",
    "%pip install tensorflow==2.13.0\n",
    "%pip install tensorflow-model-optimization==0.7.5\n",
    "# Note: Don't install tf-keras separately - use TensorFlow's built-in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ecd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Build a simple model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Apply pruning to the model\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.5, begin_step=0, end_step=1000)\n",
    "}\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# Compile the pruned model\n",
    "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the pruned model to finalize pruning\n",
    "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "pruned_model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test), callbacks=callbacks)\n",
    "\n",
    "# Strip pruning wrappers to remove pruning-specific layers and metadata\n",
    "pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361458df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to a TensorFlow Lite quantized model\n",
    "print(\"Converting to TensorFlow Lite with quantization...\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_model = converter.convert()\n",
    "\n",
    "# Save and get quantized model size\n",
    "with open('quantized_model.tflite', 'wb') as f:\n",
    "    f.write(quantized_model)\n",
    "    \n",
    "quantized_size = len(quantized_model) / 1024  # Size in KB\n",
    "print(f'Quantized model size: {quantized_size:.2f} KB')\n",
    "print(f'Size reduction: {((original_size - quantized_size) / original_size * 100):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287feda1",
   "metadata": {},
   "source": [
    "## Model Quantization\n",
    "\n",
    "Convert the pruned model to TensorFlow Lite format with quantization optimization. Quantization reduces the model size and improves inference speed by converting 32-bit floating point weights and activations to 8-bit integers, while maintaining reasonable accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure accuracy of the quantized model using the test set\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "# Evaluate accuracy\n",
    "correct_predictions = 0\n",
    "for i in range(len(x_test)):\n",
    "    input_data = x_test[i:i+1].astype('float32')\n",
    "    interpreter.set_tensor(input_index, input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_index)\n",
    "    predicted_label = output.argmax()\n",
    "    if predicted_label == y_test[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(x_test)\n",
    "print(f'Quantized model accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
