{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc413324",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow==2.13.0\n",
    "%pip install tensorflow-model-optimization==0.7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd39815",
   "metadata": {},
   "source": [
    "# 1. Performance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972609ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Build and train a simple model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(x_train, y_train, epochs=3, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Get predictions on test set\n",
    "predictions = model.predict(x_test)\n",
    "y_pred = np.argmax(predictions, axis=1)  # Convert probabilities to class labels\n",
    "y_true = y_test  # Actual labels\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "# For multi-class, use 'macro' or 'weighted' instead of 'binary'\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create sample input data - use a batch of test images\n",
    "input_data = x_test[:100]  # Take first 100 test images\n",
    "\n",
    "# Measure response time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(input_data)\n",
    "end_time = time.time()\n",
    "\n",
    "response_time = end_time - start_time\n",
    "avg_response_time = response_time / len(input_data)\n",
    "\n",
    "print(f'Total Response Time: {response_time:.4f} seconds')\n",
    "print(f'Average Response Time per image: {avg_response_time:.6f} seconds')\n",
    "print(f'Predictions per second: {len(input_data) / response_time:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32580aa6",
   "metadata": {},
   "source": [
    "# 2. Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Define pruning parameters\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0, final_sparsity=0.5, begin_step=0, end_step=1000\n",
    "    )\n",
    "}\n",
    "\n",
    "# Apply pruning to the Sequential model\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# Compile the pruned model\n",
    "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Retrain the pruned model to finalize pruning\n",
    "callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "pruned_model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test), callbacks=callbacks)\n",
    "\n",
    "# Strip pruning wrappers to remove pruning-specific layers and metadata\n",
    "pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086932f9",
   "metadata": {},
   "source": [
    "# 3 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca556958",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36208e80",
   "metadata": {},
   "source": [
    "# 4. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Flatten the MNIST images for sklearn (which expects 2D data)\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)  # Shape: (60000, 784)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)    # Shape: (10000, 784)\n",
    "\n",
    "# Create and train logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=100, random_state=42)\n",
    "\n",
    "# Use RFE to select top 100 features (pixels) - 784 pixels is too many\n",
    "print(\"Applying Recursive Feature Elimination...\")\n",
    "rfe = RFE(lr_model, n_features_to_select=100, step=50)\n",
    "rfe = rfe.fit(x_train_flat, y_train)\n",
    "\n",
    "# Transform data to use only selected features\n",
    "x_train_selected = rfe.transform(x_train_flat)\n",
    "x_test_selected = rfe.transform(x_test_flat)\n",
    "\n",
    "# Train the model with selected features\n",
    "print(\"Training model with selected features...\")\n",
    "lr_model.fit(x_train_selected, y_train)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = lr_model.score(x_test_selected, y_test)\n",
    "print(f'\\nAccuracy with {rfe.n_features_} selected features: {accuracy:.4f}')\n",
    "print(f'Selected {rfe.n_features_} out of {x_train_flat.shape[1]} total features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669f4524",
   "metadata": {},
   "source": [
    "# 5. Stress testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f90c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    print(f\"{i} - Model prediction: {model.predict(input_data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
